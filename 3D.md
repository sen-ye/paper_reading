[toc]

# NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis

**keywords:** scene representation, view synthesis, rendering, 3D deep learning

**summary:**

input: $(x, y, z, \theta, \phi)$ output: $(r, g, b, \sigma)$

<img src="E:\github_repos\paper_reading\fig\Nerf.png" alt="Nerf" style="zoom: 67%;" />

**Volume Rendering:**

the expected color of camera ray $r(t) = o + td$ is:

$C(r) = \int_{t_n}^{t_f} T(t) \sigma(r(t))c(r(t), d)dt $

where $T(t) = exp(-\int_{t_n}^{t}\sigma(r(s))ds)$

estimate the integral through sampling, partition the $[t_n, t_f]$ into N evenly-spaced bins, and sample uniformly within each bin

**Positional Encoding**

> mapping the inputs to a higher dimensional space using high frequency functions before passing them to the network enables better fitting of data that contains high frequency variation

$\gamma : \mathbb R -> \mathbb R^{2L}$

$\gamma(p) = (\sin(2^0\pi p), \cos(2^0 \pi p), \dots, \sin(2^{L-1} \pi p), \cos2^{L-1} \pi p)$

**Hierarchical Volume sampling**

optimize two networks: a coarse and a fine network

rewrite the estimated color:

$\tilde C_c (r) = \sum_{i=1}^{N_C} \omega_i c_i \ \ \ \ \omega_i = T_i(1-exp(-\sigma_i\delta_i))$

normalizing $\omega_i$ can get a pdf along the ray, then sample a second set of $N_f$ locations

**implementation details**

Loss function:

<img src="E:\github_repos\paper_reading\fig\nerf_loss.png" alt="nerf_loss" style="zoom:50%;" />

# Nerfies: Deformable Neural Radiance Fields

**keywords:** deformable scene reconstruction, Nerf, coordinate-based model

**summary:**

Deformable Neural Radiance Fields: a template volume represented by NERF; a per-observation deformation field

![Deformable_nerf](E:\github_repos\paper_reading\fig\Deformable_nerf.png)

**neural radiance fields:**

$F: (\boldsymbol x, \boldsymbol d, \boldsymbol \psi_i) \rightarrow (\boldsymbol c, \sigma)$

where $\boldsymbol \psi_i$  is an appearance latent code

**neural deformation fields**

observation-to-canonical deformation is a mapping: $T : (\boldsymbol x, \boldsymbol \omega_i) \rightarrow \boldsymbol x'$ is learned on a per-frame deformation latent code $\boldsymbol \omega_i$

$G(\boldsymbol x, \boldsymbol d, \boldsymbol \psi_i, \boldsymbol \omega_i) \triangleq F(T(\boldsymbol x, \boldsymbol \omega_i), \boldsymbol d, \boldsymbol \psi_i)$

the deformation is formulated by $\text{SE}(3): (\boldsymbol x, \boldsymbol \omega_i) \rightarrow (\boldsymbol r, \boldsymbol v)$ where $\boldsymbol r$ is an unit screw axis and $\boldsymbol v$ is the translation 

**elastic regularization**

deformation field $T$ is a non-linear mapping from observation-coordinates in $\mathbb R^3$ to canonical coordinates in $\mathbb R^3$

control the local behavior of the deformation through the Jacobian $\boldsymbol J_T(\boldsymbol x) = \boldsymbol U \boldsymbol \Sigma \boldsymbol V^T$ of this transformationz

<img src="E:\github_repos\paper_reading\fig\Deformable_nerf_loss.png" alt="Deformable_nerf_loss" style="zoom:50%;" />

<img src="E:\github_repos\paper_reading\fig\Deformable_nerf_robust_loss.png" alt="Deformable_nerf_robust_loss" style="zoom:50%;" />

**background regularization**

Given these static 3D points $\{ x_1, x_2, \dots, x_n \}$ we penalize movement as $L_{bg} = \frac{1}{K} \sum_{k=1}^{K} \Vert T(x_i) - x_i \Vert_2 $

**Coarse-to-Fine Deformation Regularization**

positional encoding can be interpreted in terms of the Neural Tangent Kernel (NTK) of NeRF's MLP: a stationary interpolating kernel where m controls a tunable "bandwidth" of that kernel. A small number of frequencies induces a wide kernel which causes under-fitting of the data, while a large number of frequencies induces a narrow kernel causing over-fitting. 

We define the weight for each frequency band $j$ as:

$w_j(\alpha) = \frac{(1-\cos(\pi\text{clamp}(\alpha-j,0,1)))}{2}$

the positional encodings is then defined as $\gamma_{\alpha}(\boldsymbol x)=(\boldsymbol x, w_k(\alpha)\sin(2^k\pi \boldsymbol x), w_k(\alpha)\cos(2^k\pi \boldsymbol x), \dots)$

# HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields

**keywords:**

**summary:**



















